# torch device
device: 'cpu'
# device: 'cuda'
hamiltonian_type: "exact" # "CPP" | "exact"
device_get_conditional_output: 'device' # "cpu" | "device"(the same with "device")

n_samples: 12288000
n_epoches: 100000
save_model: 0
save_per_epoches: 1000
load_model: 0
checkpoint_path: "none"

# 0->extract ham; 1->load ham; 2->save ham;
do_ham: 0

#model_fp: fp64
model_fp: fp32

transfer_learning: true
#transfer_learning: false
seed: 333
pos_independ: false
use_sr: false
use_clip_grad: false
psi_type: 'qk2' # qk1 | qk2
only_infer: false
search_init_best_seed: false
weak_scaling: false

# Open parallel of software
#use_uniq_sampling_parallel: true
use_uniq_sampling_parallel: false
incr_per_epoch: 50
min_partition_samples: 64
#partition_algo: 'weight'
partition_algo: 'number'

# if > 0, using max input dimension for phase
max_transfer: 0
#max_transfer: 128

use_samples_recursive: true
n_samples_min: 1e5
n_samples_max: 1e12
n_unq_samples_m1n: 1000
n_unq_samples_max: 3000
n_samples_scale_factor: 1.3

sampling_algo: "bfs"
#sampling_algo: "dfs"
sampling_dfs_width: 128
sampling_dfs_uniq_samples_min: 2048

drop_samples: false
drop_samples_eps: 1e-8

use_amp_infer_batch: true
amp_infer_batch_size: 8192

use_kv_cache: false
use_grad_accumulation: false
grad_accumulation_width: 2048
#grad_accumulation_width: 8192

# "none"/"restricted"/"unrestricted"
electron_conservation_type: "none"
qubit_order: -1
#qubit_order: 0
log_level: 'INFO' # 'INFO' | 'DEBUG'
system: 'TFI'
n_elecs: 0
elec_cons_method: 0
# default will be n_elecs/2
#n_alpha_electrons: 2 # spin-up elec
# n_beta_electrons: 2 # spin-down elec

model:
    d_model: 32
    n_layers: 8
    n_heads: 8
    p_dropout: 0.0

# phase model for QiankunNet2 (Optional)
phase_hidden_features: 256
phase_num_blocks: 1

# phase model for QiankunNet1 (Optional)
phase_hidden_size: [512,512,512,512]
use_phase_embedding: false

optim:
    name: 'AdamW'
    #lr: 0.0005
    lr: 1.0
    betas: [0.9, 0.99]
    eps: 1e-9
    weight_decay: 0.003
    open_lr_scheduler: true
    #open_lr_scheduler: false
    warmup_step: 4000
